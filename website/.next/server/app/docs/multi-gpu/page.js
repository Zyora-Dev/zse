(()=>{var e={};e.id=311,e.ids=[311],e.modules={7849:e=>{"use strict";e.exports=require("next/dist/client/components/action-async-storage.external")},2934:e=>{"use strict";e.exports=require("next/dist/client/components/action-async-storage.external.js")},5403:e=>{"use strict";e.exports=require("next/dist/client/components/request-async-storage.external")},4580:e=>{"use strict";e.exports=require("next/dist/client/components/request-async-storage.external.js")},4749:e=>{"use strict";e.exports=require("next/dist/client/components/static-generation-async-storage.external")},5869:e=>{"use strict";e.exports=require("next/dist/client/components/static-generation-async-storage.external.js")},399:e=>{"use strict";e.exports=require("next/dist/compiled/next-server/app-page.runtime.prod.js")},9717:(e,t,s)=>{"use strict";s.r(t),s.d(t,{GlobalError:()=>l.a,__next_app__:()=>u,originalPathname:()=>m,pages:()=>d,routeModule:()=>x,tree:()=>c});var i=s(482),r=s(9108),a=s(2563),l=s.n(a),o=s(8300),n={};for(let e in o)0>["default","tree","pages","GlobalError","originalPathname","__next_app__","routeModule"].indexOf(e)&&(n[e]=()=>o[e]);s.d(t,n);let c=["",{children:["docs",{children:["multi-gpu",{children:["__PAGE__",{},{page:[()=>Promise.resolve().then(s.bind(s,808)),"/Users/redfoxhotels/zse/website/src/app/docs/multi-gpu/page.tsx"]}]},{}]},{layout:[()=>Promise.resolve().then(s.bind(s,9231)),"/Users/redfoxhotels/zse/website/src/app/docs/layout.tsx"]}]},{layout:[()=>Promise.resolve().then(s.bind(s,7633)),"/Users/redfoxhotels/zse/website/src/app/layout.tsx"],"not-found":[()=>Promise.resolve().then(s.t.bind(s,9361,23)),"next/dist/client/components/not-found-error"]}],d=["/Users/redfoxhotels/zse/website/src/app/docs/multi-gpu/page.tsx"],m="/docs/multi-gpu/page",u={require:s,loadChunk:()=>Promise.resolve()},x=new i.AppPageRouteModule({definition:{kind:r.x.APP_PAGE,page:"/docs/multi-gpu/page",pathname:"/docs/multi-gpu",bundlePath:"",filename:"",appPaths:[]},userland:{loaderTree:c}})},2458:(e,t,s)=>{Promise.resolve().then(s.bind(s,757))},757:(e,t,s)=>{"use strict";s.r(t),s.d(t,{default:()=>c});var i=s(5344),r=s(1499),a=s(196),l=s(1812),o=s(9039);let n=[{id:"overview",title:"Overview",level:2},{id:"how-it-works",title:"How It Works",level:2},{id:"usage",title:"Usage",level:2},{id:"vram-distribution",title:"VRAM Distribution",level:2},{id:"benchmarks",title:"Benchmarks",level:2}];function c(){return(0,i.jsxs)("div",{className:"flex",children:[(0,i.jsxs)("article",{className:"flex-1 min-w-0 py-8 px-6 lg:px-10",children:[i.jsx(r.lv,{title:"Multi-GPU Support",description:"Run larger models by distributing weights across multiple GPUs.",badge:"Feature"}),(0,i.jsxs)(r.Je,{id:"overview",title:"Overview",children:[i.jsx("p",{className:"mb-4",children:"ZSE supports multi-GPU inference, allowing you to run models that don't fit on a single GPU by automatically sharding layers across available devices."}),(0,i.jsxs)(o.gy,{columns:3,children:[i.jsx(o.Zb,{title:"Auto Detection",description:"Automatically detects available GPUs and VRAM"}),i.jsx(o.Zb,{title:"Model Sharding",description:"Distributes layers evenly across GPUs"}),i.jsx(o.Zb,{title:"VRAM Balancing",description:"Configurable memory limits per device"})]}),i.jsx(o.VS,{features:["Automatic GPU count and memory detection","HuggingFace accelerate integration","Even layer distribution across GPUs","Configurable max_memory per GPU","Support for mixed GPU configurations"]})]}),(0,i.jsxs)(r.Je,{id:"how-it-works",title:"How It Works",children:[(0,i.jsxs)("p",{className:"mb-4",children:["Multi-GPU inference works by distributing model layers across available GPUs. ZSE uses HuggingFace's ",i.jsx(a.Z,{children:'device_map="auto"'})," under the hood for automatic layer distribution."]}),i.jsx(a.d,{language:"text",code:`Model: Qwen 32B (64 layers)
Available: 2x A10G (24GB each)

Layer Distribution:
┌─────────────┐    ┌─────────────┐
│   GPU 0     │    │   GPU 1     │
│             │    │             │
│ Layers 0-31 │    │ Layers 32-63│
│             │    │             │
│ ~12GB VRAM  │    │ ~12GB VRAM  │
└─────────────┘    └─────────────┘

Forward Pass:
Input → GPU 0 → Transfer → GPU 1 → Output`}),i.jsx(l.U,{type:"info",children:"Inter-GPU communication adds some latency, but enables running models that wouldn't fit on a single GPU. The overhead is typically 5-15%."})]}),(0,i.jsxs)(r.Je,{id:"usage",title:"Usage",children:[i.jsx(r.KU,{id:"python-api",title:"Python API",children:i.jsx(a.d,{language:"python",code:`from zse.engine.orchestrator import IntelligenceOrchestrator

# Auto-detect and use all available GPUs
orch = IntelligenceOrchestrator.multi_gpu("Qwen/Qwen2.5-Coder-7B-Instruct")
orch.load()  # Model automatically sharded across GPUs

# Or specify which GPUs to use
orch = IntelligenceOrchestrator.multi_gpu("model_name", gpu_ids=[0, 1])

# Check GPU info
info = IntelligenceOrchestrator.get_gpu_info()
print(f"GPUs: {info['count']}, Total VRAM: {info['total_memory'] / 1e9:.1f} GB")`})}),i.jsx(r.KU,{id:"cli",title:"CLI",children:i.jsx(a.d,{language:"bash",code:`# Auto-detect GPUs and distribute model
zse serve model.zse --multi-gpu

# Specify GPU IDs
zse serve model.zse --gpus 0,1,2

# Set memory limits per GPU
zse serve model.zse --multi-gpu --max-memory "0:20GB,1:20GB"`})}),i.jsx(r.KU,{id:"gpu-info",title:"Checking GPU Info",children:i.jsx(a.d,{language:"python",code:`from zse.engine.orchestrator import IntelligenceOrchestrator

info = IntelligenceOrchestrator.get_gpu_info()
# Returns:
# {
#   "count": 2,
#   "devices": [
#     {"id": 0, "name": "NVIDIA A10G", "memory": 24576000000},
#     {"id": 1, "name": "NVIDIA A10G", "memory": 24576000000}
#   ],
#   "total_memory": 49152000000
# }`})})]}),(0,i.jsxs)(r.Je,{id:"vram-distribution",title:"VRAM Distribution",children:[i.jsx("p",{className:"mb-4",children:"ZSE automatically balances VRAM usage across GPUs. You can also configure maximum memory per GPU for fine-grained control."}),i.jsx(a.d,{language:"python",code:`# Set max memory per GPU (useful for reserving memory for KV cache)
orch = IntelligenceOrchestrator.multi_gpu(
    "model_name",
    max_memory={
        0: "20GB",  # Leave 4GB for KV cache on GPU 0
        1: "22GB",  # Leave 2GB for KV cache on GPU 1
    }
)`}),i.jsx(l.U,{type:"warning",children:"Reserve some VRAM for the KV cache and CUDA kernels. Using 100% of available memory will cause out-of-memory errors during inference."})]}),(0,i.jsxs)(r.Je,{id:"benchmarks",title:"Benchmarks",children:[i.jsx("p",{className:"mb-4",children:"Verified on Modal with 2x A10G GPUs:"}),i.jsx("div",{className:"overflow-x-auto",children:(0,i.jsxs)("table",{className:"w-full text-sm",children:[i.jsx("thead",{children:(0,i.jsxs)("tr",{className:"border-b border-white/10",children:[i.jsx("th",{className:"text-left py-3 px-4 font-medium text-gray-400",children:"Test"}),i.jsx("th",{className:"text-left py-3 px-4 font-medium text-gray-400",children:"Result"})]})}),(0,i.jsxs)("tbody",{children:[(0,i.jsxs)("tr",{className:"border-b border-white/5",children:[i.jsx("td",{className:"py-3 px-4 text-white",children:"GPU Detection"}),i.jsx("td",{className:"py-3 px-4 text-lime",children:"2 GPUs detected ✓"})]}),(0,i.jsxs)("tr",{className:"border-b border-white/5",children:[i.jsx("td",{className:"py-3 px-4 text-white",children:"Model Load (Qwen 7B FP16)"}),i.jsx("td",{className:"py-3 px-4 text-lime",children:"80s ✓"})]}),(0,i.jsxs)("tr",{className:"border-b border-white/5",children:[i.jsx("td",{className:"py-3 px-4 text-white",children:"VRAM Distribution"}),i.jsx("td",{className:"py-3 px-4 text-lime",children:"GPU 0: 6.22 GB, GPU 1: 7.96 GB ✓"})]}),(0,i.jsxs)("tr",{className:"border-b border-white/5",children:[i.jsx("td",{className:"py-3 px-4 text-white",children:"Generation Speed"}),i.jsx("td",{className:"py-3 px-4 text-lime",children:"100 tokens @ 15.0 tok/s ✓"})]})]})]})}),i.jsx(l.U,{type:"info",children:"Multi-GPU is most beneficial for models larger than 30B parameters, where the memory savings outweigh the inter-GPU communication overhead."})]}),i.jsx(r.KO,{prev:{href:"/docs/zkv",title:"zKV"},next:{href:"/docs/gguf",title:"GGUF Compatibility"}})]}),i.jsx(r.o5,{items:n})]})}},9039:(e,t,s)=>{"use strict";s.d(t,{Rg:()=>o,VS:()=>n,Zb:()=>c,gy:()=>d});var i=s(5344),r=s(1912),a=s(2312),l=s(1453);function o({steps:e}){return i.jsx("div",{className:"my-6 space-y-0",children:e.map((t,s)=>(0,i.jsxs)(r.E.div,{initial:{opacity:0,y:10},animate:{opacity:1,y:0},transition:{delay:.1*s},className:"relative pl-8 pb-8 last:pb-0",children:[s<e.length-1&&i.jsx("div",{className:"absolute left-[11px] top-6 bottom-0 w-px bg-white/10"}),i.jsx("div",{className:"absolute left-0 top-0 w-6 h-6 rounded-full bg-lime/20 border border-lime/40 flex items-center justify-center",children:i.jsx("span",{className:"text-xs font-bold text-lime",children:s+1})}),(0,i.jsxs)("div",{children:[i.jsx("h4",{className:"text-base font-semibold text-white mb-1",children:t.title}),t.description&&i.jsx("p",{className:"text-sm text-white/50 mb-3",children:t.description}),t.code&&i.jsx("pre",{className:"bg-white/[0.03] border border-white/[0.06] rounded-lg p-3 overflow-x-auto my-2",children:i.jsx("code",{className:"text-sm text-lime/90 font-mono",children:t.code})}),t.content&&i.jsx("div",{className:"text-sm text-white/70",children:t.content})]})]},s))})}function n({features:e}){return i.jsx("ul",{className:"my-4 space-y-2",children:e.map((e,t)=>(0,i.jsxs)(r.E.li,{initial:{opacity:0,x:-10},animate:{opacity:1,x:0},transition:{delay:.05*t},className:"flex items-start gap-2",children:[i.jsx(a.Z,{className:"w-4 h-4 text-lime mt-0.5 flex-shrink-0"}),i.jsx("span",{className:"text-sm text-white/70",children:e})]},t))})}function c({title:e,description:t,icon:s,href:a,children:o}){let n=a?"a":"div";return i.jsx(r.E.div,{initial:{opacity:0,y:10},animate:{opacity:1,y:0},whileHover:a?{y:-2}:void 0,children:(0,i.jsxs)(n,{...a?{href:a,className:"block"}:{},className:(0,l.cn)("p-4 rounded-lg border border-white/[0.06] bg-white/[0.02]",a&&"hover:border-lime/30 hover:bg-white/[0.04] transition-all cursor-pointer"),children:[s&&i.jsx("div",{className:"w-8 h-8 rounded-lg bg-lime/10 flex items-center justify-center mb-3",children:i.jsx(s,{className:"w-4 h-4 text-lime"})}),i.jsx("h4",{className:"text-base font-semibold text-white mb-1",children:e}),t&&i.jsx("p",{className:"text-sm text-white/50",children:t}),o]})})}function d({children:e,columns:t=2}){return i.jsx("div",{className:(0,l.cn)("grid gap-4 my-6",2===t&&"md:grid-cols-2",3===t&&"md:grid-cols-3"),children:e})}},808:(e,t,s)=>{"use strict";s.r(t),s.d(t,{$$typeof:()=>a,__esModule:()=>r,default:()=>l});let i=(0,s(6843).createProxy)(String.raw`/Users/redfoxhotels/zse/website/src/app/docs/multi-gpu/page.tsx`),{__esModule:r,$$typeof:a}=i,l=i.default}};var t=require("../../../webpack-runtime.js");t.C(e);var s=e=>t(t.s=e),i=t.X(0,[638,498,697,224,782,883],()=>s(9717));module.exports=i})();