(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[7801],{6285:function(e,t,i){Promise.resolve().then(i.bind(i,5140))},5140:function(e,t,i){"use strict";i.r(t),i.d(t,{default:function(){return d}});var s=i(3827),n=i(9676),a=i(5558),l=i(4657),r=i(4987);let o=[{id:"overview",title:"Overview",level:2},{id:"quick-start",title:"Quick Start",level:2},{id:"quantization-types",title:"Quantization Types",level:2},{id:"advanced-options",title:"Advanced Options",level:2},{id:"batch-conversion",title:"Batch Conversion",level:2},{id:"quality-validation",title:"Quality Validation",level:2}];function d(){return(0,s.jsxs)("div",{className:"flex",children:[(0,s.jsxs)("article",{className:"flex-1 min-w-0 py-8 px-6 lg:px-10",children:[(0,s.jsx)(n.lv,{title:"zQuantize",description:"Convert models to optimized .zse format with extreme compression and minimal quality loss.",badge:"Feature"}),(0,s.jsxs)(n.Je,{id:"overview",title:"Overview",children:[(0,s.jsxs)("p",{className:"mb-4",children:[(0,s.jsx)(a.Z,{children:"zQuantize"})," converts transformer models from HuggingFace, safetensors, or GGUF to ZSE's native format with configurable quantization."]}),(0,s.jsx)(r.VS,{features:["4-bit and 8-bit quantization with calibration","NF4 (NormalFloat4) for best quality","Group quantization for accuracy preservation","Mixed precision for critical layers","CUDA-accelerated conversion"]})]}),(0,s.jsxs)(n.Je,{id:"quick-start",title:"Quick Start",children:[(0,s.jsx)(r.Rg,{steps:[{title:"Convert a model",description:"Run the convert command with default settings (NF4)",code:"zse convert Qwen/Qwen2.5-7B-Instruct -o qwen-7b.zse"},{title:"Verify the conversion",description:"Check model info and size",code:"zse info qwen-7b.zse"},{title:"Test the model",description:"Run a quick inference test",code:'zse chat qwen-7b.zse -p "Hello, how are you?"'}]}),(0,s.jsx)(l.U,{type:"info",children:"Conversion time depends on model size and GPU availability. A 7B model takes ~2 minutes on GPU or ~15 minutes on CPU."})]}),(0,s.jsxs)(n.Je,{id:"quantization-types",title:"Quantization Types",children:[(0,s.jsx)("p",{className:"mb-4",children:"Choose the right quantization type for your memory/quality tradeoff:"}),(0,s.jsxs)(r.gy,{columns:2,children:[(0,s.jsx)(r.Zb,{title:"NF4 (Default)",description:"Best quality 4-bit — normalized float distribution"}),(0,s.jsx)(r.Zb,{title:"INT4",description:"Standard 4-bit — fastest conversion speed"}),(0,s.jsx)(r.Zb,{title:"INT8",description:"8-bit integer — higher quality, larger files"}),(0,s.jsx)(r.Zb,{title:"FP16",description:"Half precision — maximum quality, largest files"})]}),(0,s.jsxs)(n.KU,{id:"nf4",title:"NF4 Quantization",children:[(0,s.jsx)("p",{className:"mb-2",children:"NormalFloat4 is optimized for the weight distribution of neural networks:"}),(0,s.jsx)(a.d,{language:"bash",code:"zse convert model-id -o model.zse --quant nf4"}),(0,s.jsx)(r.VS,{features:["Asymmetric quantization grid","Optimal for normally-distributed weights","Industry-leading 4-bit quality","Default for most models"]})]}),(0,s.jsxs)(n.KU,{id:"int4",title:"INT4 Quantization",children:[(0,s.jsx)("p",{className:"mb-2",children:"Standard symmetric 4-bit integer quantization:"}),(0,s.jsx)(a.d,{language:"bash",code:"zse convert model-id -o model.zse --quant int4"}),(0,s.jsx)(r.VS,{features:["Symmetric quantization grid","Faster conversion than NF4","Compatible with more hardware","Slightly lower quality than NF4"]})]}),(0,s.jsxs)(n.KU,{id:"int8",title:"INT8 Quantization",children:[(0,s.jsx)("p",{className:"mb-2",children:"8-bit quantization for higher quality:"}),(0,s.jsx)(a.d,{language:"bash",code:"zse convert model-id -o model.zse --quant int8"})]}),(0,s.jsxs)(n.KU,{id:"fp16",title:"FP16 (No Quantization)",children:[(0,s.jsx)("p",{className:"mb-2",children:"Convert without quantization — useful for fine-tuning or maximum quality:"}),(0,s.jsx)(a.d,{language:"bash",code:"zse convert model-id -o model.zse --quant fp16"})]}),(0,s.jsx)("div",{className:"overflow-x-auto my-6",children:(0,s.jsxs)("table",{className:"w-full text-sm",children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{className:"border-b border-white/10",children:[(0,s.jsx)("th",{className:"text-left py-2 pr-4 text-white/50 font-medium",children:"Type"}),(0,s.jsx)("th",{className:"text-right py-2 px-4 text-white/50 font-medium",children:"7B Size"}),(0,s.jsx)("th",{className:"text-right py-2 px-4 text-white/50 font-medium",children:"Quality"}),(0,s.jsx)("th",{className:"text-right py-2 pl-4 text-white/50 font-medium",children:"Speed"})]})}),(0,s.jsxs)("tbody",{className:"text-white/70",children:[(0,s.jsxs)("tr",{className:"border-b border-white/[0.05]",children:[(0,s.jsx)("td",{className:"py-2 pr-4",children:(0,s.jsx)(a.Z,{children:"nf4"})}),(0,s.jsx)("td",{className:"text-right py-2 px-4",children:"4.2 GB"}),(0,s.jsx)("td",{className:"text-right py-2 px-4 text-lime",children:"★★★★☆"}),(0,s.jsx)("td",{className:"text-right py-2 pl-4",children:"★★★★☆"})]}),(0,s.jsxs)("tr",{className:"border-b border-white/[0.05]",children:[(0,s.jsx)("td",{className:"py-2 pr-4",children:(0,s.jsx)(a.Z,{children:"int4"})}),(0,s.jsx)("td",{className:"text-right py-2 px-4",children:"4.0 GB"}),(0,s.jsx)("td",{className:"text-right py-2 px-4",children:"★★★☆☆"}),(0,s.jsx)("td",{className:"text-right py-2 pl-4 text-lime",children:"★★★★★"})]}),(0,s.jsxs)("tr",{className:"border-b border-white/[0.05]",children:[(0,s.jsx)("td",{className:"py-2 pr-4",children:(0,s.jsx)(a.Z,{children:"int8"})}),(0,s.jsx)("td",{className:"text-right py-2 px-4",children:"7.5 GB"}),(0,s.jsx)("td",{className:"text-right py-2 px-4 text-lime",children:"★★★★★"}),(0,s.jsx)("td",{className:"text-right py-2 pl-4",children:"★★★☆☆"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{className:"py-2 pr-4",children:(0,s.jsx)(a.Z,{children:"fp16"})}),(0,s.jsx)("td",{className:"text-right py-2 px-4",children:"14 GB"}),(0,s.jsx)("td",{className:"text-right py-2 px-4 text-lime",children:"★★★★★"}),(0,s.jsx)("td",{className:"text-right py-2 pl-4",children:"★★☆☆☆"})]})]})]})})]}),(0,s.jsxs)(n.Je,{id:"advanced-options",title:"Advanced Options",children:[(0,s.jsxs)(n.KU,{id:"group-size",title:"Group Size",children:[(0,s.jsx)("p",{className:"mb-2",children:"Control quantization granularity. Smaller groups = better quality, larger files:"}),(0,s.jsx)(a.d,{language:"bash",code:"# Default group size (128)\nzse convert model -o model.zse --quant nf4\n\n# Smaller groups for better quality\nzse convert model -o model.zse --quant nf4 --group-size 64\n\n# Larger groups for smaller files\nzse convert model -o model.zse --quant nf4 --group-size 256"})]}),(0,s.jsxs)(n.KU,{id:"calibration",title:"Calibration Dataset",children:[(0,s.jsx)("p",{className:"mb-2",children:"Use calibration data for optimal quantization ranges:"}),(0,s.jsx)(a.d,{language:"bash",code:"# Use built-in calibration (default)\nzse convert model -o model.zse --calibrate\n\n# Use custom calibration data\nzse convert model -o model.zse --calibrate-data ./prompts.txt\n\n# Skip calibration (faster, slightly lower quality)\nzse convert model -o model.zse --no-calibrate"}),(0,s.jsx)(l.U,{type:"tip",children:"Custom calibration with domain-specific data can improve quality for specialized tasks."})]}),(0,s.jsxs)(n.KU,{id:"mixed-precision",title:"Mixed Precision",children:[(0,s.jsx)("p",{className:"mb-2",children:"Keep critical layers at higher precision:"}),(0,s.jsx)(a.d,{language:"bash",code:'# Keep embedding and output layers at FP16\nzse convert model -o model.zse --quant nf4 --mixed-precision\n\n# Keep specific layers at higher precision\nzse convert model -o model.zse --quant nf4 --keep-fp16 "embed,lm_head"'})]})]}),(0,s.jsxs)(n.Je,{id:"batch-conversion",title:"Batch Conversion",children:[(0,s.jsx)("p",{className:"mb-4",children:"Convert multiple models in a script:"}),(0,s.jsx)(a.d,{language:"bash",code:'#!/bin/bash\nMODELS=(\n  "Qwen/Qwen2.5-7B-Instruct"\n  "Qwen/Qwen2.5-14B-Instruct"\n  "meta-llama/Llama-3.1-8B-Instruct"\n)\n\nfor model in "${MODELS[@]}"; do\n  name=$(basename "$model" | tr \'[:upper:]\' \'[:lower:]\')\n  zse convert "$model" -o "./models/$name.zse" --quant nf4\ndone'}),(0,s.jsx)("p",{className:"mt-4 mb-2",children:"Python API for programmatic conversion:"}),(0,s.jsx)(a.d,{language:"python",code:'from zllm_zse import convert_model\n\n# Convert with options\nconvert_model(\n    source="Qwen/Qwen2.5-7B-Instruct",\n    output="qwen-7b.zse",\n    quant="nf4",\n    group_size=128,\n    calibrate=True\n)\n\n# Convert multiple models\nmodels = ["model-a", "model-b", "model-c"]\nfor model in models:\n    convert_model(model, f"{model}.zse")'})]}),(0,s.jsxs)(n.Je,{id:"quality-validation",title:"Quality Validation",children:[(0,s.jsx)("p",{className:"mb-4",children:"Verify quantized model quality with built-in benchmarks:"}),(0,s.jsx)(a.d,{language:"bash",code:"# Run perplexity benchmark\nzse benchmark qwen-7b.zse --metric perplexity\n\n# Compare with original\nzse benchmark qwen-7b.zse --compare Qwen/Qwen2.5-7B-Instruct\n\n# Full evaluation suite\nzse benchmark qwen-7b.zse --eval mmlu,hellaswag,arc"}),(0,s.jsx)("p",{className:"mt-4",children:"Example output:"}),(0,s.jsx)(a.d,{language:"text",code:"┌─────────────────────────────────────────────────────────┐\n│ Model: qwen-7b.zse (NF4, 4.2 GB)                        │\n├─────────────────────────────────────────────────────────┤\n│ Perplexity:     5.42 (original: 5.38, Δ +0.7%)         │\n│ MMLU:           64.2% (original: 64.8%, Δ -0.6%)       │\n│ HellaSwag:      78.1% (original: 78.9%, Δ -0.8%)       │\n│ ARC-Challenge:  52.3% (original: 53.1%, Δ -0.8%)       │\n└─────────────────────────────────────────────────────────┘"}),(0,s.jsx)(l.U,{type:"success",children:"Less than 1% quality loss is typical with NF4 quantization."})]}),(0,s.jsx)(n.KO,{prev:{title:"Memory Management",href:"/docs/memory"},next:{title:"zServe",href:"/docs/zserve"}})]}),(0,s.jsx)(n.o5,{items:o})]})}},4987:function(e,t,i){"use strict";i.d(t,{Rg:function(){return r},VS:function(){return o},Zb:function(){return d},gy:function(){return c}});var s=i(3827),n=i(5293),a=i(9259),l=i(2169);function r(e){let{steps:t}=e;return(0,s.jsx)("div",{className:"my-6 space-y-0",children:t.map((e,i)=>(0,s.jsxs)(n.E.div,{initial:{opacity:0,y:10},animate:{opacity:1,y:0},transition:{delay:.1*i},className:"relative pl-8 pb-8 last:pb-0",children:[i<t.length-1&&(0,s.jsx)("div",{className:"absolute left-[11px] top-6 bottom-0 w-px bg-white/10"}),(0,s.jsx)("div",{className:"absolute left-0 top-0 w-6 h-6 rounded-full bg-lime/20 border border-lime/40 flex items-center justify-center",children:(0,s.jsx)("span",{className:"text-xs font-bold text-lime",children:i+1})}),(0,s.jsxs)("div",{children:[(0,s.jsx)("h4",{className:"text-base font-semibold text-white mb-1",children:e.title}),e.description&&(0,s.jsx)("p",{className:"text-sm text-white/50 mb-3",children:e.description}),e.code&&(0,s.jsx)("pre",{className:"bg-white/[0.03] border border-white/[0.06] rounded-lg p-3 overflow-x-auto my-2",children:(0,s.jsx)("code",{className:"text-sm text-lime/90 font-mono",children:e.code})}),e.content&&(0,s.jsx)("div",{className:"text-sm text-white/70",children:e.content})]})]},i))})}function o(e){let{features:t}=e;return(0,s.jsx)("ul",{className:"my-4 space-y-2",children:t.map((e,t)=>(0,s.jsxs)(n.E.li,{initial:{opacity:0,x:-10},animate:{opacity:1,x:0},transition:{delay:.05*t},className:"flex items-start gap-2",children:[(0,s.jsx)(a.Z,{className:"w-4 h-4 text-lime mt-0.5 flex-shrink-0"}),(0,s.jsx)("span",{className:"text-sm text-white/70",children:e})]},t))})}function d(e){let{title:t,description:i,icon:a,href:r,children:o}=e,d=r?"a":"div";return(0,s.jsx)(n.E.div,{initial:{opacity:0,y:10},animate:{opacity:1,y:0},whileHover:r?{y:-2}:void 0,children:(0,s.jsxs)(d,{...r?{href:r,className:"block"}:{},className:(0,l.cn)("p-4 rounded-lg border border-white/[0.06] bg-white/[0.02]",r&&"hover:border-lime/30 hover:bg-white/[0.04] transition-all cursor-pointer"),children:[a&&(0,s.jsx)("div",{className:"w-8 h-8 rounded-lg bg-lime/10 flex items-center justify-center mb-3",children:(0,s.jsx)(a,{className:"w-4 h-4 text-lime"})}),(0,s.jsx)("h4",{className:"text-base font-semibold text-white mb-1",children:t}),i&&(0,s.jsx)("p",{className:"text-sm text-white/50",children:i}),o]})})}function c(e){let{children:t,columns:i=2}=e;return(0,s.jsx)("div",{className:(0,l.cn)("grid gap-4 my-6",2===i&&"md:grid-cols-2",3===i&&"md:grid-cols-3"),children:t})}}},function(e){e.O(0,[5293,2150,2716,2971,8069,1744],function(){return e(e.s=6285)}),_N_E=e.O()}]);